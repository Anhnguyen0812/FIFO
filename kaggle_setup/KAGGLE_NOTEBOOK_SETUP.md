# ğŸš€ HÆ¯á»šNG DáºªN CHáº Y FIFO TRÃŠN KAGGLE - Tá»ªNG BÆ¯á»šC CHI TIáº¾T

Repository: https://github.com/Anhnguyen0812/FIFO/tree/phianh

---

## ğŸ“‹ BÆ¯á»šC 1: CHUáº¨N Bá»Š DATASET TRÃŠN KAGGLE

### 1.1 Upload Dataset
1. Truy cáº­p https://www.kaggle.com/
2. ÄÄƒng nháº­p tÃ i khoáº£n
3. Click **Datasets** â†’ **New Dataset**
4. Upload thÆ° má»¥c `cityscapes-filtered-fog` vá»›i cáº¥u trÃºc:
   ```
   cityscapes-filtered-fog/
   â”œâ”€â”€ foggy_filtered/
   â”‚   â””â”€â”€ foggy_data/
   â”‚       â””â”€â”€ leftImg8bit_foggy/
   â”‚           â”œâ”€â”€ train/
   â”‚           â””â”€â”€ val/
   â”œâ”€â”€ gtFine_filtered/
   â”‚   â””â”€â”€ gtFine_data/
   â”‚       â””â”€â”€ gtFine/
   â”‚           â”œâ”€â”€ train/
   â”‚           â””â”€â”€ val/
   â”œâ”€â”€ leftImg8bit_filtered/
   â”‚   â””â”€â”€ leftImg8bit_data/
   â”‚       â””â”€â”€ leftImg8bit/
   â”‚           â”œâ”€â”€ train/
   â”‚           â””â”€â”€ val/
   â””â”€â”€ realfog_filtered_2gb/
       â””â”€â”€ RGB/
   ```

5. **TÃªn dataset**: `cityscapes-filtered-fog` (quan trá»ng!)
6. Set **Public** hoáº·c **Private**
7. Click **Create**

### 1.2 XÃ¡c nháº­n Dataset Ä‘Ã£ upload
Sau khi upload xong, dataset sáº½ cÃ³ URL dáº¡ng:
```
https://www.kaggle.com/datasets/YOUR_USERNAME/cityscapes-filtered-fog
```

---

## ğŸ“‹ BÆ¯á»šC 2: Táº O KAGGLE NOTEBOOK CHO TEST

### 2.1 Táº¡o Notebook má»›i
1. VÃ o **Code** â†’ **New Notebook**
2. Äáº·t tÃªn: `FIFO-Test-5Images`
3. **Settings** (gÃ³c pháº£i):
   - **Accelerator**: GPU P100 hoáº·c T4
   - **Internet**: ON
   - **Persistence**: Files only

### 2.2 Add Dataset vÃ o Notebook
1. Panel bÃªn pháº£i, click **+ Add Data**
2. TÃ¬m dataset: `cityscapes-filtered-fog`
3. Click **Add**

---

## ğŸ“‹ BÆ¯á»šC 3: CHáº Y TEST Vá»šI 5 áº¢NH (CELLS TRONG KAGGLE NOTEBOOK)

### Cell 1: Clone code tá»« GitHub
```python
!git clone -b phianh https://github.com/Anhnguyen0812/FIFO.git /kaggle/working/fifo
%cd /kaggle/working/fifo
!git status
```

**Ká»³ vá»ng output**: 
```
Cloning into '/kaggle/working/fifo'...
On branch phianh
```

---

### Cell 2: Kiá»ƒm tra cáº¥u trÃºc
```bash
!ls -la /kaggle/working/fifo/
!ls -la /kaggle/working/fifo/kaggle_setup/
```

**Ká»³ vá»ng**: Tháº¥y cÃ¡c thÆ° má»¥c main.py, configs/, model/, kaggle_setup/, etc.

---

### Cell 3: Verify setup
```bash
!chmod +x /kaggle/working/fifo/kaggle_setup/verify_setup.sh
!bash /kaggle/working/fifo/kaggle_setup/verify_setup.sh
```

**Ká»³ vá»ng**: CÃ¡c check Ä‘á»u cÃ³ âœ“ (tick xanh)

---

### Cell 4: Kiá»ƒm tra dataset path
```python
import os

# Kiá»ƒm tra dataset cÃ³ tá»“n táº¡i khÃ´ng
dataset_path = '/kaggle/input/cityscapes-filtered-fog'
if os.path.exists(dataset_path):
    print(f"âœ“ Dataset found at: {dataset_path}")
    
    # List cÃ¡c thÆ° má»¥c chÃ­nh
    for item in os.listdir(dataset_path):
        full_path = os.path.join(dataset_path, item)
        print(f"  - {item}/")
else:
    print(f"âœ— Dataset NOT found at: {dataset_path}")
    print(f"\nAvailable datasets:")
    !ls -la /kaggle/input/
```

**Náº¿u dataset path khÃ¡c**, update trong file config:
```python
# Náº¿u path khÃ¡c, update biáº¿n nÃ y
KAGGLE_DATA_ROOT = '/kaggle/input/YOUR-DATASET-NAME'
```

---

### Cell 5: Install dependencies
```bash
# Fix NumPy version conflict
!pip install "numpy<2.0" -q
!pip install wandb pytorch-metric-learning tqdm -q
!pip install git+https://github.com/drsleep/DenseTorch.git -q
```

**Ká»³ vá»ng**: Install thÃ nh cÃ´ng, khÃ´ng cÃ³ ERROR

---

### Cell 6: Copy config cho test
```bash
!cp /kaggle/working/fifo/kaggle_setup/train_config_kaggle_test.py /kaggle/working/fifo/configs/train_config.py
```

---

### Cell 7: Setup Wandb (offline mode)
```python
import os
os.environ['WANDB_MODE'] = 'offline'
print("Wandb set to offline mode")
```

**LÆ°u Ã½**: Náº¿u muá»‘n dÃ¹ng Wandb online:
```python
import wandb
wandb.login(key='YOUR_WANDB_API_KEY')
```

---

### Cell 8: Táº¡o thÆ° má»¥c output
```bash
!mkdir -p /kaggle/working/snapshots/FIFO_test
!mkdir -p /kaggle/working/results
!ls -la /kaggle/working/
```

---

### Cell 9: ğŸš€ CHáº Y TEST TRAINING (50 STEPS)
```bash
%cd /kaggle/working/fifo

!python main.py \
    --file-name "test_5images" \
    --modeltrain "fogpass" \
    --batch-size 1 \
    --num-steps 50 \
    --num-steps-stop 50 \
    --save-pred-every 10 \
    --gpu 0
```

**Thá»i gian**: ~5-10 phÃºt

**Ká»³ vá»ng output**:
```
Loading datasets...
Datasets loaded successfully!
Starting training for 50 steps...
  0%|          | 0/50 [00:00<?, ?it/s]
...
taking snapshot ...
Training completed!
```

---

### Cell 10: Kiá»ƒm tra káº¿t quáº£
```python
import glob
import os

# Check snapshots
snapshot_dir = '/kaggle/working/snapshots/FIFO_test'
checkpoints = glob.glob(f'{snapshot_dir}/*.pth')

print(f"Found {len(checkpoints)} checkpoint(s):")
for ckpt in sorted(checkpoints):
    size = os.path.getsize(ckpt) / (1024**2)  # MB
    print(f"  - {os.path.basename(ckpt)} ({size:.2f} MB)")

# Load vÃ  kiá»ƒm tra checkpoint
if checkpoints:
    import torch
    latest_ckpt = sorted(checkpoints)[-1]
    print(f"\nLoading checkpoint: {latest_ckpt}")
    
    checkpoint = torch.load(latest_ckpt, map_location='cpu')
    print(f"Keys in checkpoint: {list(checkpoint.keys())}")
    print(f"Training iteration: {checkpoint.get('train_iter', 'N/A')}")
    print("âœ“ Checkpoint valid!")
```

**Ká»³ vá»ng**: Tháº¥y cÃ¡c file .pth vÃ  load thÃ nh cÃ´ng

---

## âœ… Náº¾U TEST THÃ€NH CÃ”NG â†’ CHUYá»‚N SANG FULL TRAINING

Náº¿u Cell 9 cháº¡y thÃ nh cÃ´ng khÃ´ng lá»—i, tiáº¿p tá»¥c vá»›i Full Training!

---

## ğŸ“‹ BÆ¯á»šC 4: CHáº Y FULL TRAINING (NOTEBOOK Má»šI)

### 4.1 Táº¡o Notebook má»›i cho Full Training
1. **Save Version** notebook test (Ä‘á»ƒ backup)
2. Táº¡o notebook má»›i: `FIFO-Full-Training`
3. **Settings** (QUAN TRá»ŒNG):
   - **Accelerator**: **GPU T4 x2** (khuyáº¿n nghá»‹)
   - **Internet**: ON
   - **Persistence**: **Files only** (Ä‘á»ƒ giá»¯ checkpoints)

### 4.2 Add Dataset
- Add dataset `cityscapes-filtered-fog` (giá»‘ng test)

---

### FULL TRAINING CELLS

### Cell 1: Clone code
```python
!git clone -b phianh https://github.com/Anhnguyen0812/FIFO.git /kaggle/working/fifo
%cd /kaggle/working/fifo
```

### Cell 2: Install dependencies
```bash
# Fix NumPy version conflict
!pip install "numpy<2.0" -q
!pip install wandb pytorch-metric-learning tqdm -q
!pip install git+https://github.com/drsleep/DenseTorch.git -q
```

### Cell 3: Copy config FULL
```bash
!cp /kaggle/working/fifo/kaggle_setup/train_config_kaggle.py /kaggle/working/fifo/configs/train_config.py
```

### Cell 4: Setup Wandb
```python
import os
os.environ['WANDB_MODE'] = 'offline'
```

### Cell 5: Táº¡o thÆ° má»¥c
```bash
!mkdir -p /kaggle/working/snapshots/FIFO_model
!mkdir -p /kaggle/working/results
```

### Cell 6: Kiá»ƒm tra GPU
```python
import torch
print(f"PyTorch version: {torch.__version__}")
print(f"CUDA available: {torch.cuda.is_available()}")
print(f"GPU count: {torch.cuda.device_count()}")
if torch.cuda.is_available():
    for i in range(torch.cuda.device_count()):
        print(f"GPU {i}: {torch.cuda.get_device_name(i)}")
```

**Ká»³ vá»ng**: GPU count = 2 (náº¿u chá»n T4 x2)

---

### Cell 7: ğŸš€ STAGE 1 - Train FogPassFilter (20,000 steps)
```bash
%cd /kaggle/working/fifo

!python main.py \
    --file-name "fifo_fogpass_stage1" \
    --modeltrain "fogpass" \
    --batch-size 4 \
    --num-steps 20000 \
    --num-steps-stop 20000 \
    --save-pred-every 5000 \
    --gpu 0
```

**Thá»i gian**: ~4-6 giá»
**Checkpoint**: Táº¡o file `*_fogpassfilter_5000.pth`

---

### Cell 8: TÃ¬m checkpoint FogPassFilter
```python
import glob

checkpoint_dir = '/kaggle/working/snapshots/FIFO_model'
fogpass_checkpoints = sorted(glob.glob(f'{checkpoint_dir}/*fogpassfilter*.pth'))

if fogpass_checkpoints:
    latest_fogpass = fogpass_checkpoints[-1]
    print(f"âœ“ Found FogPassFilter checkpoint: {latest_fogpass}")
    print(f"Will use this for Stage 2")
else:
    print("âœ— No FogPassFilter checkpoint found!")
    print("Please check Stage 1 completed successfully")
```

---

### Cell 9: ğŸš€ STAGE 2 - Train Full Model (60,000 steps)
```python
import glob

# TÃ¬m checkpoint
fogpass_ckpt = sorted(glob.glob('/kaggle/working/snapshots/FIFO_model/*fogpassfilter*.pth'))[-1]
print(f"Using checkpoint: {fogpass_ckpt}")

# Cháº¡y training
!python main.py \
    --file-name "fifo_full_stage2" \
    --modeltrain "train" \
    --batch-size 4 \
    --num-steps 60000 \
    --num-steps-stop 60000 \
    --save-pred-every 5000 \
    --restore-from-fogpass {fogpass_ckpt} \
    --gpu 0
```

**Thá»i gian**: ~12-18 giá»
**Checkpoints**: LÆ°u má»—i 5000 iterations

---

### Cell 10: Kiá»ƒm tra táº¥t cáº£ checkpoints
```python
import glob
import os

checkpoint_dir = '/kaggle/working/snapshots/FIFO_model'
all_checkpoints = sorted(glob.glob(f'{checkpoint_dir}/*.pth'))

print(f"Total checkpoints: {len(all_checkpoints)}\n")

for ckpt in all_checkpoints:
    name = os.path.basename(ckpt)
    size = os.path.getsize(ckpt) / (1024**2)  # MB
    print(f"  {name}")
    print(f"    Size: {size:.2f} MB")
    print()
```

---

## ğŸ’¾ BÆ¯á»šC 5: LÆ¯U Káº¾T QUáº¢

### CÃ¡ch 1: Commit Notebook (Khuyáº¿n nghá»‹)
1. Click **Save Version** á»Ÿ gÃ³c trÃªn
2. Chá»n **Save & Run All (Commit)**
3. Äá»£i notebook cháº¡y xong
4. VÃ o **Output** tab
5. Download cÃ¡c file `.pth`

### CÃ¡ch 2: Copy vÃ o thÆ° má»¥c output
```python
# Cell má»›i
!mkdir -p /kaggle/working/fifo_checkpoints
!cp /kaggle/working/snapshots/FIFO_model/*.pth /kaggle/working/fifo_checkpoints/
!ls -lh /kaggle/working/fifo_checkpoints/
```

Sau Ä‘Ã³ commit notebook, output sáº½ thÃ nh dataset cÃ³ thá»ƒ download.

---

## ğŸ”„ TIáº¾P Tá»¤C TRAINING (RESUME)

Náº¿u notebook timeout hoáº·c muá»‘n tiáº¿p tá»¥c:

### Cell má»›i: Resume Training
```python
import glob
import torch

# TÃ¬m checkpoint má»›i nháº¥t
all_ckpts = sorted(glob.glob('/kaggle/working/snapshots/FIFO_model/*FIFO*.pth'))
if all_ckpts:
    latest_ckpt = all_ckpts[-1]
    print(f"Resuming from: {latest_ckpt}")
    
    # Load Ä‘á»ƒ check iteration
    ckpt_data = torch.load(latest_ckpt, map_location='cpu')
    current_iter = ckpt_data.get('train_iter', 0)
    print(f"Current iteration: {current_iter}")
    print(f"Will continue to: 60000")
    
    # Resume training
    !python main.py \
        --file-name "fifo_resume" \
        --modeltrain "train" \
        --batch-size 4 \
        --num-steps 60000 \
        --num-steps-stop 60000 \
        --save-pred-every 5000 \
        --restore-from {latest_ckpt} \
        --restore-from-fogpass {latest_ckpt} \
        --gpu 0
else:
    print("No checkpoint found to resume!")
```

---

## ğŸ› TROUBLESHOOTING

### Lá»—i: "Dataset not found"
```python
# Kiá»ƒm tra tÃªn dataset
!ls /kaggle/input/

# Náº¿u tÃªn khÃ¡c, update config
# Sá»­a file: configs/train_config.py
# DÃ²ng: KAGGLE_DATA_ROOT = '/kaggle/input/TEN-MOI'
```

### Lá»—i: "ModuleNotFoundError"
```bash
!pip install wandb pytorch-metric-learning tqdm -q
!pip install git+https://github.com/drsleep/DenseTorch.git -q
```

### Lá»—i: "CUDA out of memory"
```python
# Giáº£m batch_size
# Thay --batch-size 4 thÃ nh --batch-size 2 hoáº·c 1
```

### Lá»—i: "No such file or directory" cho test_5images
```bash
# Kiá»ƒm tra file tá»“n táº¡i
!cat /kaggle/working/fifo/dataset/cityscapes_list/test_5images_foggy.txt
!cat /kaggle/working/fifo/dataset/cityscapes_list/test_5images_origin.txt
```

### Checkpoint khÃ´ng táº£i Ä‘Æ°á»£c
```python
import torch
ckpt_path = "PATH_TO_CHECKPOINT.pth"
try:
    ckpt = torch.load(ckpt_path, map_location='cpu')
    print("âœ“ Checkpoint loaded")
    print(f"Keys: {list(ckpt.keys())}")
except Exception as e:
    print(f"âœ— Error: {e}")
```

---

## ğŸ“Š MONITOR TRAINING

### Xem logs trong Notebook
- Output hiá»ƒn thá»‹ real-time trong cell
- Progress bar tá»« tqdm
- Loss values Ä‘Æ°á»£c in ra

### Kiá»ƒm tra GPU usage
```bash
# Cell riÃªng, cháº¡y song song
!watch -n 5 nvidia-smi
```

### Check tiáº¿n trÃ¬nh
```python
import glob
checkpoints = glob.glob('/kaggle/working/snapshots/FIFO_model/*FIFO*.pth')
print(f"Checkpoints saved: {len(checkpoints)}")
for ckpt in sorted(checkpoints)[-3:]:  # 3 má»›i nháº¥t
    print(f"  - {os.path.basename(ckpt)}")
```

---

## â±ï¸ THá»œI GIAN Æ¯á»šC TÃNH

| Stage | Steps | GPU | Time |
|-------|-------|-----|------|
| **Test** | 50 | T4 | 5-10 min |
| **Stage 1 (FogPass)** | 20K | T4 | 4-6 hours |
| **Stage 2 (Full)** | 60K | T4 | 12-18 hours |
| **Total Full Training** | 80K | T4 | **16-24 hours** |

**Kaggle Limits**:
- GPU T4 x2: 30 hours/week
- CÃ³ thá»ƒ chia thÃ nh nhiá»u session

---

## âœ… CHECKLIST TRÆ¯á»šC KHI CHáº Y

### Test (5 áº£nh):
- [ ] Dataset `cityscapes-filtered-fog` Ä‘Ã£ upload
- [ ] Dataset Ä‘Ã£ add vÃ o notebook
- [ ] Code clone tá»« branch `phianh`
- [ ] GPU Ä‘Ã£ enable
- [ ] Dependencies installed
- [ ] Verify setup passed

### Full Training:
- [ ] Test cháº¡y thÃ nh cÃ´ng
- [ ] Notebook má»›i vá»›i GPU T4 x2
- [ ] Persistence: Files only
- [ ] Äá»§ quota (check Kaggle settings)
- [ ] Config file Ä‘Ã£ copy Ä‘Ãºng

---

## ğŸ¯ Káº¾T QUáº¢ MONG Äá»¢I

Sau khi hoÃ n thÃ nh, báº¡n sáº½ cÃ³:
1. **~16 checkpoint files** (.pth)
2. **Final model**: iteration 60000
3. **File size**: má»—i checkpoint ~500-800MB
4. **Model trained**: Segmentation + FogPassFilter

---

## ğŸ“ Há»– TRá»¢

Náº¿u gáº·p lá»—i:
1. Copy error message Ä‘áº§y Ä‘á»§
2. Check cell output
3. Run verify_setup.sh
4. Check Kaggle logs

**Repository**: https://github.com/Anhnguyen0812/FIFO/tree/phianh

---

**ChÃºc báº¡n training thÃ nh cÃ´ng! ğŸš€ğŸ‰**
