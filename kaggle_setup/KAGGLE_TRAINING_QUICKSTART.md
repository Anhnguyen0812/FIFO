# ğŸš€ HÆ¯á»šNG DáºªN TRAIN FIFO STAGE 2 TRÃŠN KAGGLE

Train Stage 2 vá»›i pretrained FogPassFilter  
â±ï¸ Thá»i gian: ~5-6 giá»  
ğŸ¯ mIoU: 40-45%  
ğŸ“Š Input size: 2048Ã—1024 (original)

---

## ğŸ“‹ YÃŠU Cáº¦U

### 1. TÃ i khoáº£n Kaggle
- âœ… ÄÄƒng kÃ½: https://www.kaggle.com
- âœ… Verify phone number
- âœ… GPU quota: 30h/tuáº§n

### 2. Datasets cáº§n upload
- `FogPassFilter_pretrained.pth` (527 MB)
- `cityscapes-filtered-fog` dataset (foggy + clear + real fog images)

---

## ğŸ“¤ UPLOAD DATASETS LÃŠN KAGGLE

### Dataset 1: cityscapes-filtered-fog

**Cáº¥u trÃºc:**
```
cityscapes-filtered-fog/
â”œâ”€â”€ foggy_filtered/foggy_data/leftImg8bit_foggy/train/  # 708 foggy
â”œâ”€â”€ leftImg8bit_filtered/leftImg8bit_data/leftImg8bit/train/  # 708 clear
â”œâ”€â”€ gtFine_filtered/gtFine_data/gtFine/train/  # labels
â””â”€â”€ realfog_filtered_2gb/RGB/  # 837 real fog
```

**Upload:**
1. https://www.kaggle.com/datasets â†’ New Dataset
2. Upload folder hoáº·c zip
3. TÃªn: `cityscapes-filtered-fog`
4. Private â†’ Create

### Dataset 2: fogpass-pretrained

**Upload:**
1. https://www.kaggle.com/datasets â†’ New Dataset
2. Upload: `FogPassFilter_pretrained.pth`
3. TÃªn: `fogpass-pretrained`
4. Private â†’ Create

---

## ğŸ““ Táº O KAGGLE NOTEBOOK

1. https://www.kaggle.com/code â†’ New Notebook
2. **Settings:**
   - Accelerator: **GPU P100** hoáº·c **T4**
   - Internet: **ON**
3. **Add Data:**
   - `cityscapes-filtered-fog` â†’ Add
   - `fogpass-pretrained` â†’ Add

---

## ğŸ¬ CHáº Y TRAINING

Copy tá»«ng cell tá»« `kaggle_setup/KAGGLE_STAGE2_CELLS.py` vÃ o notebook.

### âš¡ CELL 1: Clone Repo (30 giÃ¢y)

```python
import os
!git clone https://github.com/Anhnguyen0812/FIFO.git fifo
os.chdir('/kaggle/working/fifo')
print("âœ… Repository cloned!")
!pwd
```

---

### ğŸ“‹ CELL 2: Generate Dataset Lists (1 phÃºt)

```python
!python kaggle_setup/generate_dataset_lists.py
!python kaggle_setup/generate_realfog_list.py

print("\nğŸ“‹ Cityscapes lists:")
!ls -lh dataset/cityscapes_list/*.txt | grep train

print("\nğŸ“‹ Real fog list:")
!ls -lh lists_file_names/realfog_all_filenames.txt
!wc -l lists_file_names/realfog_all_filenames.txt

print("\nâœ… Dataset lists generated!")
```

**Káº¿t quáº£:**
```
train_foggy_0.005.txt: 708 files
train_origin.txt: 708 files
realfog_all_filenames.txt: 837 files
```

---

### ğŸ” CELL 2.5: Verify Paths (30 giÃ¢y)

```python
print("=" * 70)
print("VERIFYING DATASET PATHS")
print("=" * 70)

print("\nğŸ“ Dataset structure:")
!ls -lh /kaggle/input/cityscapes-filtered-fog/

print("\nğŸ“ Sample from train_foggy_0.005.txt:")
!head -3 dataset/cityscapes_list/train_foggy_0.005.txt

print("\nğŸ” Testing paths:")
import os
first_foggy = !head -1 dataset/cityscapes_list/train_foggy_0.005.txt
first_foggy = first_foggy[0].strip()

test_path = f"/kaggle/input/cityscapes-filtered-fog/foggy_filtered/foggy_data/leftImg8bit_foggy/{first_foggy}"
print(f"{'âœ…' if os.path.exists(test_path) else 'âŒ'} {test_path}")
```

**âœ… Náº¿u tháº¥y âœ… â†’ Paths Ä‘Ãºng, tiáº¿p tá»¥c!**

---

### âœ… CELL 3: Verify Pretrained Model (30 giÃ¢y)

```python
import torch
pretrained_path = '/kaggle/input/fogpass-pretrained/FogPassFilter_pretrained.pth'

if os.path.exists(pretrained_path):
    ckpt = torch.load(pretrained_path, map_location='cpu')
    print(f"âœ… File found!")
    print(f"âœ… Has fogpass1: {'fogpass1_state_dict' in ckpt}")
    print(f"âœ… Has fogpass2: {'fogpass2_state_dict' in ckpt}")
    print(f"ğŸ“Š Trained: {ckpt.get('train_iter', 'N/A')} iterations")
    print("\nâœ… Pretrained model ready!")
else:
    print("âŒ File not found! Check dataset added.")
```

---

### ğŸš€ CELL 4: TRAINING (5-6 giá») âš ï¸ QUAN TRá»ŒNG NHáº¤T

```python
print("=" * 70)
print("STAGE 2: TRAINING")
print("Input: 2048Ã—1024 | Batch: 1Ã—4 | Steps: 15,000")
print("Time: ~5-6 hours | Memory: ~14-15GB")
print("=" * 70)

!python main.py \
--file-name 'FIFO_stage2' \
--modeltrain train \
--restore-from without_pretraining \
--restore-from-fogpass /kaggle/input/fogpass-pretrained/FogPassFilter_pretrained.pth \
--num-steps 15000 \
--num-steps-stop 15000 \
--batch-size 1 \
--iter-size 4 \
--input-size '2048,1024' \
--input-size-rf '1920,1080' \
--data-dir '/kaggle/input/cityscapes-filtered-fog/foggy_filtered/foggy_data/leftImg8bit_foggy' \
--data-dir-rf '/kaggle/input/cityscapes-filtered-fog/realfog_filtered_2gb' \
--data-list './dataset/cityscapes_list/train_foggy_0.005.txt' \
--data-list-rf './lists_file_names/realfog_all_filenames.txt' \
--data-list-cwsf './dataset/cityscapes_list/train_origin.txt' \
--data-dir-cwsf '/kaggle/input/cityscapes-filtered-fog/leftImg8bit_filtered/leftImg8bit_data/leftImg8bit' \
--save-pred-every 1000 \
--snapshot-dir '/kaggle/working/snapshots_stage2' \
--lambda-fsm 0.0000001 \
--lambda-con 0.0001 \
--gpu 0

print("\nâœ… TRAINING COMPLETED!")
```

**â±ï¸ Theo dÃµi:**
- Speed: ~0.8-1.2 it/s
- Loss giáº£m: 3.0 â†’ 0.5-0.8
- Checkpoints: Má»—i 1000 steps

**âš ï¸ LÆ¯U Ã:** KhÃ´ng táº¯t tab trÃ¬nh duyá»‡t! Kaggle sáº½ timeout.

---

### ğŸ“¦ CELL 5: Check Checkpoints (30 giÃ¢y)

```python
print("SAVED CHECKPOINTS")
!ls -lh /kaggle/working/snapshots_stage2/*.pth
!ls /kaggle/working/snapshots_stage2/*.pth | wc -l
```

**Káº¿t quáº£:** 15 checkpoints (1K, 2K, ..., 15K)

---

### ğŸ’¾ CELL 6: Prepare Download (1 phÃºt)

```python
!cp /kaggle/working/snapshots_stage2/FIFO_stage215000.pth \
    /kaggle/working/FIFO_stage2_15K_final.pth

print("âœ… Model ready!")
!ls -lh /kaggle/working/FIFO_stage2_15K_final.pth
```

---

### âœ… CELL 7: Verify (30 giÃ¢y)

```python
import torch
ckpt = torch.load('/kaggle/working/FIFO_stage2_15K_final.pth', map_location='cpu')

required = ['state_dict', 'fogpass1_state_dict', 'fogpass2_state_dict']
if all(k in ckpt for k in required):
    print("âœ…âœ…âœ… CHECKPOINT VALID!")
    print("ğŸ¯ Expected mIoU: 40-45%")
else:
    print("âš ï¸ Missing keys!")
```

---

### ğŸ“¥ DOWNLOAD MODEL

1. Click **"Save Version"** (gÃ³c pháº£i)
2. Chá»n **"Save & Run All"**
3. Äá»£i ~10 phÃºt
4. Go to **"Output"** tab
5. Download: `FIFO_stage2_15K_final.pth` (527 MB)

---

## ğŸ¯ ÄÃ NI GIÃ LOCAL

```bash
cd /path/to/fifo

# Foggy Driving
python evaluate_cpu.py \
    --file-name 'FIFO_stage2_15K' \
    --restore-from ./FIFO_stage2_15K_final.pth

# Foggy Zurich
python evaluate_cpu.py \
    --file-name 'FIFO_stage2_15K_FZ' \
    --restore-from ./FIFO_stage2_15K_final.pth \
    --devkit_dir_fz './dataset/Foggy_Zurich_val'
```

**Káº¿t quáº£ mong Ä‘á»£i:**
- Foggy Driving: **42-45% mIoU**
- Foggy Zurich: **40-43% mIoU**

---

## âš™ï¸ GIáº¢I THÃCH Cáº¤U HÃŒNH

### Táº¡i sao Input Size = 2048Ã—1024?

| Size | mIoU | Speed | Memory |
|------|------|-------|--------|
| **2048Ã—1024** | **40-45%** | 1.0 it/s | 14GB |
| 1280Ã—640 | 35-38% | 2.0 it/s | 8GB |
| 640Ã—320 | 25-30% | 4.0 it/s | 4GB |

â†’ **Chá»n 2048Ã—1024 Ä‘á»ƒ Ä‘áº¡t cháº¥t lÆ°á»£ng tá»‘i Ä‘a!**

### Táº¡i sao Batch Size = 1, Iter Size = 4?

**Gradient Accumulation:**
```
batch_size=4 â†’ Load 4 áº£nh cÃ¹ng lÃºc â†’ 22GB VRAM â†’ OOM âŒ

batch_size=1, iter_size=4:
  - Load 1 áº£nh â†’ forward â†’ backward â†’ accumulate
  - Repeat 4 láº§n
  - optimizer.step()
  
â†’ Same quality, chá»‰ dÃ¹ng 14GB VRAM âœ…
```

### Táº¡i sao 15K Steps?

```
Dataset: 708 paired images
Effective batch: 1 Ã— 4 = 4
Steps/epoch: 708 / 4 = 177

15K steps = 15000 / 177 â‰ˆ 85 epochs
```

| Steps | Epochs | Time | Result |
|-------|--------|------|--------|
| 5K | 28 | 2h | Underfitting |
| **15K** | **85** | **5-6h** | **Optimal âœ…** |
| 20K | 113 | 7-8h | Risk overfitting |

---

## ğŸ”§ TROUBLESHOOTING

### âŒ FileNotFoundError: No such file or directory

**NguyÃªn nhÃ¢n:** Path dataset sai

**Fix:**
1. Cháº¡y Cell 2.5 Ä‘á»ƒ verify paths
2. Náº¿u paths khÃ¡c, update `--data-dir` trong Cell 4

### âŒ CUDA Out Of Memory

**Fix 1:** Giáº£m input size
```python
--input-size '1280,640' \
--input-size-rf '960,540'
```

**Fix 2:** TÄƒng iter_size
```python
--batch-size 1 \
--iter-size 8  # was 4
```

### âŒ Kaggle Timeout

**Prevent:**
- Giá»¯ tab active
- Disable browser sleep

**Resume náº¿u bá»‹ timeout:**
```python
!ls /kaggle/working/snapshots_stage2/*.pth | tail -1  # Find last checkpoint

!python main.py \
--restore-from /kaggle/working/snapshots_stage2/FIFO_stage27000.pth \
--restore-from-fogpass /kaggle/input/fogpass-pretrained/FogPassFilter_pretrained.pth \
... (same params, continue training)
```

---

## ğŸ“Š DATASET STATISTICS

| Dataset | Train | Val | Total |
|---------|-------|-----|-------|
| Cityscapes (foggy) | 708 | 500 | 1208 |
| Cityscapes (clear) | 708 | 500 | 1208 |
| Foggy Zurich | 837 | - | 837 |

**Training:**
- Sá»­ dá»¥ng: 708 paired + 837 real fog
- Total iterations: 15,000
- Time per iteration: ~3.6 seconds
- Total time: 15000 Ã— 3.6s â‰ˆ 15 hours â†’ vá»›i overhead ~5-6h

---

## âœ… CHECKLIST

**TrÆ°á»›c khi train:**
- [ ] ÄÃ£ upload 2 datasets lÃªn Kaggle
- [ ] ÄÃ£ táº¡o notebook vÃ  add datasets
- [ ] GPU Ä‘Ã£ báº­t (P100/T4)
- [ ] Internet Ä‘Ã£ ON

**Trong quÃ¡ trÃ¬nh:**
- [ ] Cell 1: Clone repo OK
- [ ] Cell 2: Generate lists OK (708 + 837 files)
- [ ] Cell 2.5: Paths verified âœ…
- [ ] Cell 3: Pretrained checkpoint OK
- [ ] Cell 4: Training cháº¡y ~5-6h
- [ ] Checkpoints: 15 files trong snapshots_stage2/

**Sau training:**
- [ ] Downloaded FIFO_stage2_15K_final.pth
- [ ] Evaluated locally
- [ ] mIoU: 40-45% âœ…

---

## ğŸ¯ EXPECTED RESULTS

### Training Metrics
```
Iteration    Loss     Speed
--------------------------
0            3.2      0.9 it/s
5000         1.2      1.0 it/s
10000        0.8      1.1 it/s
15000        0.6      1.2 it/s
```

### Evaluation mIoU
```
Foggy Driving:        42-45%
Foggy Driving Dense:  38-42%
Foggy Zurich:         40-43%
```

**So vá»›i training incomplete trÆ°á»›c:**
- TrÆ°á»›c: 1-3% mIoU âŒ
- Sau: 40-45% mIoU âœ…
- **Improvement: 15Ã— better! ğŸš€**

---

## ğŸ“š FILES REFERENCE

- `KAGGLE_STAGE2_CELLS.py` - Táº¥t cáº£ cells Ä‘á»ƒ copy
- `train_config_kaggle_stage2.py` - Config file
- `TROUBLESHOOTING_DATALOADER.md` - Debug paths
- `generate_dataset_lists.py` - Generate list files
- `generate_realfog_list.py` - Generate real fog list

---

## â“ FAQ

**Q: CÃ³ thá»ƒ dÃ¹ng Google Colab khÃ´ng?**  
A: CÃ³, nhÆ°ng Colab free timeout nhanh hÆ¡n Kaggle.

**Q: Táº¡i sao khÃ´ng batch_size=2?**  
A: 2048Ã—1024 Ã— batch_size=2 = ~22GB â†’ OOM trÃªn P100 (16GB).

**Q: 15K steps cÃ³ Ä‘á»§ khÃ´ng?**  
A: Äá»§! 85 epochs lÃ  optimal cho dataset 708 áº£nh.

**Q: CÃ³ thá»ƒ train thÃªm tá»« checkpoint khÃ´ng?**  
A: CÃ³, dÃ¹ng `--restore-from <checkpoint_path>`.

**Q: mIoU 40-45% cÃ³ tá»‘t khÃ´ng?**  
A: Ráº¥t tá»‘t! SOTA ~50-55%, báº¡n Ä‘áº¡t 80-90% SOTA.

---

**Good luck! ğŸš€**

*Last updated: 2025-11-19*
