"""
FIFO Training Configuration - STAGE 2 ONLY (Using Pretrained FogPassFilter)
=============================================================================
This config is for training ONLY Stage 2 (full segmentation model) 
using pretrained FogPassFilter from FogPassFilter_pretrained.pth

IMPORTANT: 
- FogPassFilter_pretrained.pth must be uploaded to Kaggle
- This skips Stage 1 training entirely
- Original input size 2048x1024 preserved for maximum quality
- Batch size = 1 due to memory constraints on Kaggle P100/T4
"""

import argparse
import numpy as np

# ============================================================================
# IMAGE PREPROCESSING
# ============================================================================
IMG_MEAN = np.array((104.00698793, 116.66876762, 122.67891434), dtype=np.float32)
BETA = 0.005

# ============================================================================
# KAGGLE PATHS
# ============================================================================
KAGGLE_DATA_ROOT = '/kaggle/input/cityscapes-filtered-fog'

DATA_DIRECTORY = KAGGLE_DATA_ROOT
DATA_LIST_PATH = f'./dataset/cityscapes_list/train_foggy_{BETA}.txt'
DATA_CITY_PATH = './dataset/cityscapes_list/clear_lindau.txt'
DATA_DIRECTORY_CWSF = f'{KAGGLE_DATA_ROOT}/leftImg8bit_filtered/leftImg8bit_data'
DATA_LIST_PATH_CWSF = './dataset/cityscapes_list/train_origin.txt'
DATA_LIST_RF = './realfog_all_filenames.txt'  # Generated by generate_realfog_list.py
DATA_DIR = KAGGLE_DATA_ROOT

# ============================================================================
# INPUT SIZE - ORIGINAL (MAXIMUM QUALITY)
# ============================================================================
INPUT_SIZE = '2048,1024'      # Cityscapes original resolution
INPUT_SIZE_RF = '1920,1080'   # Foggy Zurich original resolution

# ============================================================================
# BATCH SIZE & WORKERS - OPTIMIZED FOR KAGGLE P100/T4
# ============================================================================
# With input size 2048x1024:
# - P100 (16GB): batch_size=1 with iter_size=4 (gradient accumulation)
# - T4 (16GB): batch_size=1 with iter_size=4
# Effective batch size = batch_size * iter_size = 4

BATCH_SIZE = 1        # Physical batch size per iteration
ITER_SIZE = 4         # Gradient accumulation steps (effective batch = 4)
NUM_WORKERS = 4       # CPU workers for data loading

# ============================================================================
# MODEL CONFIGURATION
# ============================================================================
NUM_CLASSES = 19      # Cityscapes semantic segmentation classes

# CRITICAL: Use pretrained FogPassFilter (skip Stage 1)
# Upload FogPassFilter_pretrained.pth to Kaggle as dataset
RESTORE_FROM = 'without_pretraining'  # Segmentation model starts from ImageNet
RESTORE_FROM_FOGPASS = '/kaggle/input/fogpass-pretrained/FogPassFilter_pretrained.pth'

# ============================================================================
# TRAINING STEPS - STAGE 2 ONLY
# ============================================================================
# Stage 2: Full model training (segmentation + fogpass)
# With ~500-800 images and effective batch size = 4:
# - 10K steps ≈ 50-80 epochs (optimal)
# - 15K steps ≈ 75-120 epochs (good balance)
# - 20K steps ≈ 100-160 epochs (risk overfitting on small dataset)

NUM_STEPS = 15000         # Total training steps for Stage 2
NUM_STEPS_STOP = 15000    # Stop at 15K (no early stopping)

# ============================================================================
# CHECKPOINT SAVING
# ============================================================================
SAVE_PRED_EVERY = 1000    # Save checkpoint every 1K steps (15 checkpoints total)
SNAPSHOT_DIR = '/kaggle/working/snapshots_stage2'

# ============================================================================
# TRAINING MODE
# ============================================================================
# 'train' = Stage 2 (full model with segmentation)
TRAINING_MODE = 'train'

# ============================================================================
# LOSS WEIGHTS
# ============================================================================
LAMBDA_FSM = 0.0000001    # Fog-pass Style Matching loss weight
LAMBDA_CON = 0.0001       # Consistency loss weight (KL divergence)

# ============================================================================
# OPTIMIZER SETTINGS
# ============================================================================
LEARNING_RATE = 2.5e-4    # Learning rate for segmentation model
POWER = 0.9               # Polynomial decay power
MOMENTUM = 0.9            # SGD momentum
WEIGHT_DECAY = 0.0005     # L2 regularization

# ============================================================================
# RANDOM SEED
# ============================================================================
RANDOM_SEED = 1234
SET = 'train'

# ============================================================================
# GPU
# ============================================================================
GPU = 0

def get_arguments():
    """
    Parse command line arguments for Stage 2 training
    """
    parser = argparse.ArgumentParser(description="FIFO Stage 2 Training (Pretrained FogPassFilter)")

    # Data loading
    parser.add_argument("--batch-size", type=int, default=BATCH_SIZE,
                        help="Physical batch size (use iter-size for gradient accumulation)")
    parser.add_argument("--iter-size", type=int, default=ITER_SIZE,
                        help="Gradient accumulation steps (effective batch = batch-size * iter-size)")
    parser.add_argument("--num-workers", type=int, default=NUM_WORKERS,
                        help="Number of data loading workers")
    
    # Dataset paths
    parser.add_argument("--data-dir", type=str, default=DATA_DIRECTORY,
                        help="Root directory of foggy cityscapes dataset")
    parser.add_argument("--data-list", type=str, default=DATA_LIST_PATH,
                        help="List of foggy training images")
    parser.add_argument("--data-city-list", type=str, default=DATA_CITY_PATH,
                        help="List of clear city images")
    parser.add_argument("--data-list-rf", type=str, default=DATA_LIST_RF,
                        help="List of real fog images (Foggy Zurich)")
    parser.add_argument("--data-dir-cwsf", type=str, default=DATA_DIRECTORY_CWSF,
                        help="Directory of clear weather images")
    parser.add_argument("--data-list-cwsf", type=str, default=DATA_LIST_PATH_CWSF,
                        help="List of clear weather training images")
    parser.add_argument("--data-dir-rf", type=str, default=DATA_DIR,
                        help="Root directory for real fog dataset")
    
    # Input size
    parser.add_argument("--input-size", type=str, default=INPUT_SIZE,
                        help="Input size for Cityscapes (width,height)")
    parser.add_argument("--input-size-rf", type=str, default=INPUT_SIZE_RF,
                        help="Input size for Foggy Zurich (width,height)")
    
    # Model configuration
    parser.add_argument("--num-classes", type=int, default=NUM_CLASSES,
                        help="Number of semantic classes")
    
    # Training steps
    parser.add_argument("--num-steps", type=int, default=NUM_STEPS,
                        help="Total number of training iterations")
    parser.add_argument("--num-steps-stop", type=int, default=NUM_STEPS_STOP,
                        help="Early stopping iteration (set equal to num-steps for no early stop)")
    
    # Checkpointing
    parser.add_argument("--random-seed", type=int, default=RANDOM_SEED,
                        help="Random seed for reproducibility")
    parser.add_argument("--restore-from", type=str, default=RESTORE_FROM,
                        help="Pretrained segmentation model (use 'without_pretraining' for ImageNet)")
    parser.add_argument("--restore-from-fogpass", type=str, default=RESTORE_FROM_FOGPASS,
                        help="Pretrained FogPassFilter checkpoint path")
    parser.add_argument("--save-pred-every", type=int, default=SAVE_PRED_EVERY,
                        help="Save checkpoint every N iterations")
    parser.add_argument("--snapshot-dir", type=str, default=SNAPSHOT_DIR,
                        help="Directory to save model checkpoints")
    
    # GPU
    parser.add_argument("--gpu", type=int, default=GPU,
                        help="GPU device ID")
    
    # Dataset split
    parser.add_argument("--set", type=str, default=SET,
                        help="Dataset split (train/val/test)")
    
    # Loss weights
    parser.add_argument("--lambda-fsm", type=float, default=LAMBDA_FSM,
                        help="Weight for Fog-pass Style Matching loss")
    parser.add_argument("--lambda-con", type=float, default=LAMBDA_CON,
                        help="Weight for consistency loss (KL divergence)")
    
    # Required arguments
    parser.add_argument("--file-name", type=str, required=True,
                        help="Base name for saved checkpoint files")
    parser.add_argument("--modeltrain", type=str, required=True,
                        help="Training mode: 'train' for Stage 2 (full model)")
    
    return parser.parse_args()

# ============================================================================
# USAGE EXAMPLE
# ============================================================================
"""
Stage 2 Training Command (on Kaggle):

!python main.py \\
    --file-name 'FIFO_stage2' \\
    --modeltrain train \\
    --restore-from without_pretraining \\
    --restore-from-fogpass /kaggle/input/fogpass-pretrained/FogPassFilter_pretrained.pth \\
    --num-steps 15000 \\
    --num-steps-stop 15000 \\
    --batch-size 1 \\
    --iter-size 4 \\
    --input-size '2048,1024' \\
    --input-size-rf '1920,1080' \\
    --save-pred-every 1000 \\
    --snapshot-dir '/kaggle/working/snapshots_stage2' \\
    --lambda-fsm 0.0000001 \\
    --lambda-con 0.0001 \\
    --gpu 0

EXPECTED RESULTS:
- Training time: ~5-6 hours on P100 (~1.0 it/s with batch=1, iter_size=4)
- Memory usage: ~14-15GB (fits on P100/T4 with 16GB VRAM)
- Final mIoU: ~40-45% on test sets (high quality due to original resolution)
- Checkpoints: snapshots_stage2/FIFO_stage2_1000.pth ... FIFO_stage2_15000.pth

WHY THIS CONFIGURATION:
1. Original input size (2048x1024) = maximum quality, best mIoU
2. Batch size 1 + iter_size 4 = effective batch size 4 (same as Stage 1)
3. 15K steps = optimal for ~500-800 images (75-120 epochs)
4. Pretrained FogPassFilter = saves ~2 hours (skip Stage 1)
5. Checkpoints every 1K steps = easy to pick best model

MEMORY OPTIMIZATION:
- batch_size=1: Processes 1 image at a time
- iter_size=4: Accumulates gradients over 4 iterations before optimizer.step()
- Result: Same training quality as batch_size=4, but 4x less VRAM usage

KAGGLE SETUP:
1. Upload FogPassFilter_pretrained.pth as Kaggle dataset
2. Add dataset to notebook: "+ Add Data" → search "fogpass-pretrained"
3. Dataset will be mounted at /kaggle/input/fogpass-pretrained/
"""
