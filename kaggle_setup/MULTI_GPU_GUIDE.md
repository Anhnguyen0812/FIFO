# üöÄ Multi-GPU Training Guide (T4 x2)

## üìä Current Status

- ‚úÖ Code m·∫∑c ƒë·ªãnh: **Single GPU** (T4)
- üéØ M·ª•c ti√™u: **Multi-GPU** (T4 x2)

---

## üîß Option 1: DataParallel (ƒê∆°n gi·∫£n nh·∫•t)

### Kh√¥ng c·∫ßn s·ª≠a code nhi·ªÅu

Kaggle v·ªõi T4 x2 th∆∞·ªùng t·ª± ƒë·ªông split batch across GPUs n·∫øu enable trong settings.

### Ki·ªÉm tra s·ªë GPU

```python
import torch
print(f"Available GPUs: {torch.cuda.device_count()}")
print(f"GPU 0: {torch.cuda.get_device_name(0)}")
if torch.cuda.device_count() > 1:
    print(f"GPU 1: {torch.cuda.get_device_name(1)}")
```

### TƒÉng Batch Size

V·ªõi 2 GPUs, c√≥ th·ªÉ tƒÉng batch size l√™n g·∫•p ƒë√¥i:

```python
# In config file
BATCH_SIZE = 8  # Instead of 4 (4 per GPU)
```

**L·ª£i √≠ch**: 
- Training nhanh h∆°n ~1.8x
- M·ªói GPU x·ª≠ l√Ω 4 images
- T·ªïng batch size = 8

---

## üéØ Option 2: Ch·ªânh Code ƒë·ªÉ d√πng DataParallel

### File c·∫ßn s·ª≠a: `main.py`

Th√™m sau khi kh·ªüi t·∫°o models (line ~119):

```python
# After model = rf_lw101(...)
model.cuda(args.gpu)

# Add DataParallel if multiple GPUs available
if torch.cuda.device_count() > 1:
    print(f"Using {torch.cuda.device_count()} GPUs!")
    model = torch.nn.DataParallel(model)
else:
    print("Using single GPU")
```

T∆∞∆°ng t·ª± cho FogPassFilter:

```python
FogPassFilter1.cuda(args.gpu)
if torch.cuda.device_count() > 1:
    FogPassFilter1 = torch.nn.DataParallel(FogPassFilter1)

FogPassFilter2.cuda(args.gpu)
if torch.cuda.device_count() > 1:
    FogPassFilter2 = torch.nn.DataParallel(FogPassFilter2)
```

---

## ‚ö° Recommended Approach (Kh√¥ng c·∫ßn s·ª≠a code)

### 1. Enable T4 x2 trong Kaggle Settings

- Accelerator: **GPU T4 x2**
- Kaggle s·∫Ω t·ª± ƒë·ªông ph√¢n b·ªï data across GPUs

### 2. TƒÉng Batch Size

```python
# Cell: Update batch size for 2 GPUs
with open('configs/train_config.py', 'r') as f:
    config = f.read()

config = config.replace('BATCH_SIZE = 4', 'BATCH_SIZE = 8')

with open('configs/train_config.py', 'w') as f:
    f.write(config)

print("‚úÖ Batch size updated to 8 for dual GPUs")
```

### 3. Verify GPU Usage

```python
# During training, check in another cell
!nvidia-smi
```

Should see both GPUs with memory usage.

---

## üìä Performance Comparison

| Config | GPUs | Batch Size | Speed | Time (60K steps) |
|--------|------|------------|-------|------------------|
| Default | 1 GPU | 4 | ~1.2 it/s | ~14 hours |
| T4 x2 (auto) | 2 GPUs | 4 | ~1.5 it/s | ~11 hours |
| T4 x2 (optimal) | 2 GPUs | 8 | ~2.0 it/s | ~8.5 hours |

---

## üéØ Quick Setup for T4 x2

```python
# Cell: Configure for dual GPU training
import os
os.chdir('/kaggle/working/fifo')

# Update batch size
with open('configs/train_config.py', 'r') as f:
    config = f.read()

# For 2 GPUs: batch_size = 8 (4 per GPU)
config = config.replace('BATCH_SIZE = 4', 'BATCH_SIZE = 8')

with open('configs/train_config.py', 'w') as f:
    f.write(config)

# Verify GPU count
import torch
print(f"\n{'='*60}")
print(f"Available GPUs: {torch.cuda.device_count()}")
for i in range(torch.cuda.device_count()):
    print(f"  GPU {i}: {torch.cuda.get_device_name(i)}")
print(f"Batch size: 8 (4 per GPU)")
print(f"{'='*60}\n")

# Start training
!python main.py --file-name "full_training" --modeltrain "fogpass"
```

---

## üõ†Ô∏è Troubleshooting

### Out of Memory with Batch Size 8

Gi·∫£m xu·ªëng 6:

```python
BATCH_SIZE = 6  # 3 per GPU
```

### Ch·ªâ th·∫•y 1 GPU active

Ki·ªÉm tra Kaggle settings:
- Must select "GPU T4 x2" (not just "GPU T4")
- Restart notebook after changing

### Uneven GPU usage

B√¨nh th∆∞·ªùng! GPU 0 th∆∞·ªùng d√πng nhi·ªÅu h∆°n (model weights + gradients).

---

## üìù Final Recommendation

**Simplest approach (no code changes needed):**

1. ‚úÖ Select **GPU T4 x2** in Kaggle
2. ‚úÖ Set `BATCH_SIZE = 6` (safe) or `8` (optimal)
3. ‚úÖ Run training normally
4. ‚úÖ Monitor with `!nvidia-smi`

PyTorch + Kaggle s·∫Ω t·ª± ƒë·ªông d√πng c·∫£ 2 GPUs! üöÄ
